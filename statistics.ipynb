{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('raw_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: How many r's are in the word strawberry?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deepseek-r1\n",
    "\n",
    "We assess different model parameters being 1.5B , 7B , 8B , 671B Parameter Model.\n",
    "\n",
    "Depending on parameter size we are sometiems acheive C-O-T processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 B Model Parameter\n",
    "df_deepseek_7b = df[df[\"model_name\"] == \"deepseek-r1:7b\"]\n",
    "# 1.5 B Model Parameter\n",
    "df_deepseek_1_5b = df[df[\"model_name\"] == \"deepseek-r1:1.5b\"]\n",
    "# 8 B Model Parameter\n",
    "df_deepseek_8b = df[df[\"model_name\"] == \"deepseek-r1:8b\"]\n",
    "\n",
    "#filter for only strawberry prompt\n",
    "df_deepseek_7b_strawberry = df_deepseek_7b[df_deepseek_7b[\"prompt\"] == \"How many r's are in the word strawberry?\"]\n",
    "df_deepseek_1_5b_strawberry = df_deepseek_1_5b[df_deepseek_1_5b[\"prompt\"] == \"How many r's are in the word strawberry?\"]\n",
    "df_deepseek_8b_strawberry = df_deepseek_8b[df_deepseek_8b[\"prompt\"] == \"How many r's are in the word strawberry?\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.5 B Model Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_name</th>\n",
       "      <th>iteration_no</th>\n",
       "      <th>average_token_count</th>\n",
       "      <th>min_max_token_variance_%</th>\n",
       "      <th>average_tps</th>\n",
       "      <th>average_inference_time</th>\n",
       "      <th>sample_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4651ffa4-7782-405a-bc59-b975cb9aea67</td>\n",
       "      <td>How many r's are in the word strawberry?</td>\n",
       "      <td>deepseek-r1:1.5b</td>\n",
       "      <td>10</td>\n",
       "      <td>178.7</td>\n",
       "      <td>47.081712</td>\n",
       "      <td>53.166395</td>\n",
       "      <td>3.361146</td>\n",
       "      <td>&lt;think&gt; I need to determine how many times the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bef53a95-5ffb-4464-8d1e-e59023e5ac4d</td>\n",
       "      <td>How many r's are in the word strawberry?</td>\n",
       "      <td>deepseek-r1:1.5b</td>\n",
       "      <td>10</td>\n",
       "      <td>180.9</td>\n",
       "      <td>67.346939</td>\n",
       "      <td>55.004890</td>\n",
       "      <td>3.288798</td>\n",
       "      <td>&lt;think&gt; To determine how many times the letter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              prompt_id  \\\n",
       "1  4651ffa4-7782-405a-bc59-b975cb9aea67   \n",
       "2  bef53a95-5ffb-4464-8d1e-e59023e5ac4d   \n",
       "\n",
       "                                     prompt        model_name  iteration_no  \\\n",
       "1  How many r's are in the word strawberry?  deepseek-r1:1.5b            10   \n",
       "2  How many r's are in the word strawberry?  deepseek-r1:1.5b            10   \n",
       "\n",
       "   average_token_count  min_max_token_variance_%  average_tps  \\\n",
       "1                178.7                 47.081712    53.166395   \n",
       "2                180.9                 67.346939    55.004890   \n",
       "\n",
       "   average_inference_time                                      sample_output  \n",
       "1                3.361146  <think> I need to determine how many times the...  \n",
       "2                3.288798  <think> To determine how many times the letter...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deepseek_1_5b_strawberry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>model_name</th>\n",
       "      <th>iteration_no</th>\n",
       "      <th>average_token_count</th>\n",
       "      <th>min_max_token_variance_%</th>\n",
       "      <th>average_tps</th>\n",
       "      <th>average_inference_time</th>\n",
       "      <th>sample_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [prompt_id, prompt, model_name, iteration_no, average_token_count, min_max_token_variance_%, average_tps, average_inference_time, sample_output]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_deepseek_7b_strawberry.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
